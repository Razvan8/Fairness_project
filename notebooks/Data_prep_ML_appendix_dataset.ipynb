{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../libs/\")\n",
    "from data_prep import *\n",
    "from ML_functions import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing for the appendix dataset that I will use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['X1', 'X2', 'X3', 'X4', 'X5', 'X6', 'X7', 'X8', 'X9', 'X10', 'X11',\n",
      "       'X12', 'X13', 'X14', 'X15', 'X16', 'X17', 'X18', 'X19', 'X20', 'X21',\n",
      "       'X22', 'X23', 'Y'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "########### RUN THIS CELL ONLY ONCE !\n",
    "\n",
    "\n",
    "##Tests \n",
    "def test1(value): ## Test to group by age\n",
    "    if value>=35:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def tested(value): ## Test to group by education\n",
    "    if value <=2 :\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "###\n",
    "\n",
    "# Specify the file path\n",
    "file_path = \"../Dataframes/Appendix_dataset/defaults.xls\"\n",
    "\n",
    "# Read the Excel file into a DataFrame and do some preprocessing\n",
    "df = pd.read_excel(file_path, index_col=0)\n",
    "print(df.columns)\n",
    "df=apply_function_to_column(df=df,column_name=\"X5\",test_function=test1, new_name=\"Age_group\") \n",
    "df=apply_function_to_column(df=df,column_name=\"X3\",test_function=tested, new_name=\"Education_group\") \n",
    "y = df[\"Y\"].to_frame().copy()\n",
    "num_features=[\"X1\", \"X5\"] + [f\"X{i}\" for i in range (12,24,1)] +[\"Y\"] #Y should not be dummied\n",
    "cat_features=[col_name for col_name in df.columns if col_name not in num_features]\n",
    "\n",
    "df[\"X2\"]=df[\"X2\"]-1\n",
    "\n",
    "df = pd.get_dummies(df, columns = cat_features, drop_first= True)\n",
    "X = df.drop(\"Y\", axis=1).copy()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Do train test split to get train val and test sets. \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size = 0.4, random_state=123)\n",
    "X_val,X_test,y_val,y_test=train_test_split(X_test,y_test, test_size=0.5, random_state=123) ##this make 0.2 for both val and test\n",
    "\n",
    "\n",
    "## Save sensitive attributes\n",
    "\n",
    "gender_train=X_train[\"X2_1\"]\n",
    "age_train=X_train[\"Age_group_1\"]\n",
    "\n",
    "gender_test=X_test[\"X2_1\"]\n",
    "age_test=X_test[\"Age_group_1\"]\n",
    "\n",
    "gender_val=X_val[\"X2_1\"]\n",
    "age_val=X_val[\"Age_group_1\"]\n",
    "\n",
    "\n",
    "education_train=X_train[\"X3_1\"]\n",
    "education_test=X_test[\"X3_1\"]\n",
    "education_val=X_val[\"X3_1\"]\n",
    "\n",
    "#Drop columns for without attribute and redundant ones\n",
    "\n",
    "X_train_with_A=X_train.copy() #X with sensitive_attributes\n",
    "X_test_with_A=X_test.copy() #X with sensitive_attributes\n",
    "X_val_with_A=X_val.copy() #X with sensitive_attributes\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Store the processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframes saved in their directory from 'Dataframes' directory.\n"
     ]
    }
   ],
   "source": [
    "store_data(dataset_name='Appendix_dataset',X_train_with_A=X_train_with_A,  X_val_with_A=X_val_with_A, X_test_with_A = X_test_with_A, y_train =  y_train,\n",
    "            y_val = y_val, y_test = y_test, age=[age_train, age_val, age_test],\n",
    "            gender= [gender_train, gender_val, gender_test], education=[education_train, education_val, education_test])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find and save best model for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model Hyperparameters: {'C': 0.1, 'penalty': 'l2'}\n",
      "Validation Accuracy: 0.8211666666666667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['..\\\\ML_models\\\\Appendix_dataset\\\\best_logistic_regression_A_model.pkl']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# I kept commented the other models just to show that I tried more models in the beginning\n",
    "\n",
    "\n",
    "####SCALE\n",
    "X_train_with_A, X_val_with_A, X_test_with_A = scale_dataframes(\n",
    "    [X_train_with_A, X_val_with_A, X_test_with_A])  ###scale all dfs ##Take care scale keeps 0,1 true\n",
    "\n",
    "\n",
    "############# find best model\n",
    "\n",
    "#param_grid_rf = {\n",
    "    #'n_estimators': [10,50, 100],\n",
    "    #'max_depth': [5,10],\n",
    "    #'min_samples_leaf': [ 8,16]\n",
    "#}\n",
    "\n",
    "\n",
    "#param_grid_svc = {\n",
    "    #'C': [0.1, 1, 10],\n",
    "    #'kernel': ['linear']\n",
    "#}\n",
    "\n",
    "#param_grid_knn = {\n",
    "    #'n_neighbors': [3,5, 10, 20]\n",
    "#}\n",
    "\n",
    "\n",
    "param_grid_lr = {\n",
    "    'C': [ 0.001,0.01,0.1,1],\n",
    "    'penalty': ['l2',\n",
    "    ]\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#model_rf=RandomForestClassifier()\n",
    "#model_knn = KNeighborsClassifier()\n",
    "model_lr = LogisticRegression(max_iter=500)  \n",
    "\n",
    "\n",
    "\n",
    "#best_rf_A = find_best_model(model_rf, param_grid_rf, X_train_with_A, y_train.values.ravel(),  X_val_with_A, y_val.values.ravel())\n",
    "#best_knn_A = find_best_model(model_knn, param_grid_knn, X_train_with_A, y_train.values.ravel(), X_val_with_A, y_val.values.ravel() )\n",
    "best_lr_A = find_best_model(model_lr, param_grid_lr, X_train_with_A, y_train.values.ravel(),  X_val_with_A, y_val.values.ravel())\n",
    "\n",
    "\n",
    "dataset_name=\"Appendix_dataset\"\n",
    "# Define the directory path for saving models\n",
    "models_directory = os.path.join( '..', 'ML_models', dataset_name)  # '..' moves one directory up\n",
    "\n",
    "\n",
    "if not os.path.exists(models_directory):\n",
    "    os.makedirs(models_directory)\n",
    "\n",
    "# Save the best models to separate files\n",
    "#joblib.dump(best_rf_A, os.path.join(models_directory, 'best_random_forest_A_model.pkl'))\n",
    "#joblib.dump(best_knn_A, os.path.join(models_directory, 'best_knn_A_model.pkl'))\n",
    "joblib.dump(best_lr_A, os.path.join(models_directory, 'best_logistic_regression_A_model.pkl'))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
